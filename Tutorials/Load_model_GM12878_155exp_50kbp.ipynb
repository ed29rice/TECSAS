{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDjmyKDNi9vz"
   },
   "outputs": [],
   "source": "# Install required dependencies for TECSAS\nimport os\nos.system('pip install -q glob2==0.7 requests pytest-shutil==1.7.0 pyBigWig urllib3==1.26.14 tqdm==4.64.1 joblib==1.2.0 ipywidgets==8.0.4 biopython')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kC3g5hLi_Uf"
   },
   "outputs": [],
   "source": "# Clone the TECSAS repository\n!rm -r TECSAS/\n!git clone https://github.com/ed29rice/TECSAS.git"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShVGVF5lrgmV"
   },
   "outputs": [],
   "source": "# Import the TECSAS module\nimport TECSAS.TECSAS as TECSAS"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKS2xWrTjWLs"
   },
   "outputs": [],
   "source": "# Import necessary libraries for data processing and model evaluation\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LogNorm\nimport matplotlib.colors as colors\nfrom tempfile import TemporaryDirectory\nimport torch\nfrom torch import nn, Tensor\nimport torch.nn.functional as F\nfrom torch.nn import TransformerEncoder, TransformerEncoderLayer\nfrom torch.utils.data import dataset\nfrom torch.nn import functional as F\nfrom sklearn.metrics import confusion_matrix"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_E6BBGxnFi8"
   },
   "outputs": [],
   "source": "# Set path to training data and model parameters\ndpath='./'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3zaDk9Eoi_Xc"
   },
   "outputs": [],
   "source": "# Define model hyperparameters and initialize the TECSAS model\n# Model configuration for GM12878 with 155 experiments at 50kbp resolution\nn_neigbors = 14  # Number of neighboring genomic bins on each side\nn_predict = 3  # Number of bins to predict\nNEXP = 155  # Number of experiments (features)\nnbatches = 4000  # Number of batches for training\n\n# Transformer architecture parameters\nemsize = 128  # Embedding dimension\nd_hid = 64  # Hidden dimension in feedforward network\nnlayers = 2  # Number of transformer encoder layers\nnhead = 8  # Number of attention heads\ndropout = 0.01  # Dropout rate\nnfeatures = NEXP*(2*n_neigbors+1)  # Total input features\nostates = 5  # Output states (subcompartment classes: A1, A2, B1, B2, B3)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = TECSAS.TECSAS(n_predict, emsize, nhead, d_hid, nlayers, nfeatures, ostates, dropout).to(device)\n\nmodel_parameters = filter(lambda p: p.requires_grad, model.parameters())\nparams = sum([np.prod(p.size()) for p in model_parameters])\nprint('Number of params:',params)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXaEcWEtjXaO"
   },
   "outputs": [],
   "source": "# Load pre-trained model weights for GM12878\n# Adjust keys to match the model architecture\ndict_p=torch.load(dpath+'/bv_GM12878_155.pt',map_location=torch.device('cpu'))\ntmp_dict={}\nfor k in dict_p.keys():\n    tmp_dict['.'.join(k.split('.')[1:])]=dict_p[k]\n\nmodel.load_state_dict(tmp_dict)\nmodel.eval()  # Set model to evaluation mode"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCDYtB6ftcKt"
   },
   "outputs": [],
   "source": "# Load training information and test data from checkpoint\ncheckpoint = torch.load(dpath+'/training_info_set_155.pt')\nepoch = checkpoint['epoch']\nloss = checkpoint['best_val_loss']\ntrain_data = checkpoint['train_data']\ntest_data = checkpoint['test_data']\nntest_loci = checkpoint['ntest_loci']  # Genomic loci indices for test set\nloci_indx = checkpoint['loci_indx']"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9XMoQh2HtwEd"
   },
   "outputs": [],
   "source": "# Count trainable parameters in the model\nmodel_parameters = filter(lambda p: p.requires_grad, model.parameters())\nparams = sum([np.prod(p.size()) for p in model_parameters])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyLVyGg3uiGd"
   },
   "outputs": [],
   "source": "# Helper function to extract batches from test data\ndef get_batch_test(source: Tensor, i: int, n_predict: int, ndxs=None ):\n    # Extract input features (all experiments across neighboring bins)\n    data = source[i*bptt:(i+1)*bptt,2*(n_predict-1)+1:][:,:,np.newaxis]\n    # Extract target labels (subcompartment annotations)\n    target = source[i*bptt:(i+1)*bptt,:2*(n_predict-1)+1]\n    # Extract genomic loci indices\n    indexes = ndxs[i*bptt:(i+1)*bptt]\n    return data.to(device), target.to(device), indexes"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "nWkl2RiVtwG8"
   },
   "outputs": [],
   "source": "# Evaluate model predictions on GM12878 test set at 50kbp resolution\nbptt = len(train_data)//nbatches  # Batch size\nnbatches_eval=len(test_data)//bptt\nl=[]  # Predictions\nlt=[]  # Ground truth labels\nfailed_inputs=[]\nfailed_targets=[]\nfailed_pred=[]\nfailed_loci=[]\nsuc_inputs=[]\nsuc_targets=[]\nsuc_pred=[]\nsuc_loci=[]\nwith torch.no_grad():\n    for batch in range(nbatches_eval):\n        data, targets, batch_loci = get_batch_test(test_data, batch,n_predict=n_predict, ndxs=ntest_loci)\n        if batch%10==0: print(batch, nbatches_eval, len(targets))\n        # Get model predictions (argmax over subcompartment classes)\n        prediction=model(data,None)[0].argmax(dim=-1)[:,n_predict-1].cpu()\n        # Separate failed predictions\n        idx=prediction!=targets[:,n_predict-1].cpu()\n        failed_inputs.append(targets[idx,n_predict-1].cpu())\n        failed_targets.append(data[idx].cpu())\n        failed_pred.append(prediction[idx])\n        failed_loci.append(batch_loci[idx])\n        # Separate successful predictions\n        idx=prediction==targets[:,n_predict-1].cpu()\n        suc_inputs.append(targets[idx,n_predict-1].cpu())\n        suc_targets.append(data[idx].cpu())\n        suc_pred.append(prediction[idx])\n        suc_loci.append(batch_loci[idx])\n        l.append(prediction)\n        lt.append(targets[:,n_predict-1].cpu())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wUhUSuJ1xr6O"
   },
   "outputs": [],
   "source": "# Concatenate all predictions and separate successful/failed cases\nfailed_inputs=np.concatenate(failed_inputs)\nfailed_pred=np.concatenate(failed_pred)\nfailed_targets=np.concatenate(failed_targets)\nfailed_loci=np.concatenate(failed_loci)\nsuc_inputs=np.concatenate(suc_inputs)\nsuc_pred=np.concatenate(suc_pred)\nsuc_targets=np.concatenate(suc_targets)\nsuc_loci=np.concatenate(suc_loci)\nl=np.concatenate(l)\nlt=np.concatenate(lt)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "nKfZPdILxwau"
   },
   "outputs": [],
   "source": "# Calculate and display overall accuracy for subcompartment prediction\nprint('BT Accuracy:')\nprint('test:',np.round(np.sum(l==lt)/len(l),4))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gjwmhWcMxy7u"
   },
   "outputs": [],
   "source": "# Generate confusion matrices for subcompartment predictions\n# BT: 5-class subcompartment classification (A1, A2, B1, B2, B3)\nconf_matrix_P=np.round(confusion_matrix(l,lt,normalize='true'),2)\nprint('BT Confusion matrix:')\nprint(conf_matrix_P)\n\n# AB: Binary A/B compartment classification\nconf_matrix_P=np.round(confusion_matrix(l>1,lt>1,normalize='true'),2)\nprint('AB Confusion matrix:')\nprint(conf_matrix_P)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TB6nzaIr4NY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyNaXmF5vHPh10ZYg/IEHmJQ"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}