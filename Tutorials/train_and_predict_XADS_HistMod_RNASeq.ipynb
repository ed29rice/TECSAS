{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgqwffpoNaej"
   },
   "outputs": [],
   "source": [
    "# Install required dependencies for TECSAS\n",
    "import os\n",
    "os.system('pip install -q glob2==0.7 requests pytest-shutil==1.7.0 pyBigWig urllib3==1.26.14 tqdm==4.64.1 joblib==1.2.0 ipywidgets==8.0.4 biopython')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBDVPTnGNSj9"
   },
   "outputs": [],
   "source": [
    "# Clone the TECSAS repository\n",
    "!rm -r TECSAS/\n",
    "!git clone https://github.com/ed29rice/TECSAS.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XiwtfGWONXwM"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import TECSAS.TECSAS as TECSAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7uQjyh8hExjq"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "dpath='/content/drive/MyDrive/TECSAS/XADs_HistMod_RNASeq/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5WsufbMNisV"
   },
   "outputs": [],
   "source": [
    "# Unzip genomic data for all cell lines\n",
    "!unzip /content/drive/MyDrive/TECSAS/XADs_HistMod_RNASeq/K562_GRCh38_zscore_all.zip\n",
    "!unzip /content/drive/MyDrive/TECSAS/XADs_HistMod_RNASeq/H1_GRCh38_zscore_all.zip\n",
    "!unzip /content/drive/MyDrive/TECSAS/XADs_HistMod_RNASeq/HCT116_GRCh38_zscore_all.zip\n",
    "!unzip /content/drive/MyDrive/TECSAS/XADs_HistMod_RNASeq/IMR-90_GRCh38_zscore_all.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18ZUSdVgTsEN"
   },
   "outputs": [],
   "source": [
    "#Predict only using Histone Modifications ChIP-Seq and RNASeq experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6rDMWVYSMe-"
   },
   "outputs": [],
   "source": [
    "# Filter K562 experiments to use only histone modifications\n",
    "# Backup original experiment list and create new one with selected histones\n",
    "!mv ./K562_GRCh38_zscore_all/unique_exp.txt ./K562_GRCh38_zscore_all/_unique_exp.txt\n",
    "!echo H2AFZ >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K27ac >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K27me3 >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K36me3 >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K4me1 >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K4me2 >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K4me3 >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K79me2 >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K9ac >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K9me3 >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H4K20me1 >> ./K562_GRCh38_zscore_all/unique_exp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPBTCY_lSUBI"
   },
   "outputs": [],
   "source": [
    "# Filter H1 experiments to use only histone modifications\n",
    "!mv ./H1_GRCh38_zscore_all/unique_exp.txt ./H1_GRCh38_zscore_all/_unique_exp.txt\n",
    "!echo H2AFZ >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K27ac >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K27me3 >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K36me3 >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K4me1 >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K4me2 >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K4me3 >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K79me2 >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K9ac >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K9me3 >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H4K20me1 >> ./H1_GRCh38_zscore_all/unique_exp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4fk-XsX_SUFl"
   },
   "outputs": [],
   "source": [
    "# Filter HCT116 experiments to use only histone modifications\n",
    "!mv ./HCT116_GRCh38_zscore_all/unique_exp.txt ./HCT116_GRCh38_zscore_all/_unique_exp.txt\n",
    "!echo H2AFZ >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K27ac >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K27me3 >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K36me3 >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K4me1 >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K4me2 >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K4me3 >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K79me2 >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K9ac >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K9me3 >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H4K20me1 >> ./HCT116_GRCh38_zscore_all/unique_exp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uE2fsJeMSZiE"
   },
   "outputs": [],
   "source": [
    "# Filter IMR-90 experiments to use only histone modifications\n",
    "!mv ./IMR-90_GRCh38_zscore_all/unique_exp.txt ./IMR-90_GRCh38_zscore_all/_unique_exp.txt\n",
    "!echo H2AFZ >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K27ac >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K27me3 >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K36me3 >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K4me1 >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K4me2 >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K4me3 >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K79me2 >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K9ac >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H3K9me3 >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
    "!echo H4K20me1 >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vyy38ljoNFhZ"
   },
   "outputs": [],
   "source": [
    "# Import required libraries and define helper functions for training\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "import os, sys\n",
    "import copy\n",
    "import time\n",
    "import seaborn as sns\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import dataset\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# Custom normalization class for color mapping\n",
    "class MidpointNormalize(colors.Normalize):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        colors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        # I'm ignoring masked values and all kinds of edge cases to make a\n",
    "        # simple example...\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "\n",
    "# Extract training batch from data\n",
    "def get_batch(source: Tensor, i: int, n_predict: int) -> Tuple[Tensor, Tensor]:\n",
    "    data = source[i*bptt:(i+1)*bptt,2*(n_predict-1)+1:][:,:,np.newaxis]\n",
    "    target = source[i*bptt:(i+1)*bptt,:2*(n_predict-1)+1]\n",
    "    return data.to(device), target.to(device)\n",
    "\n",
    "# Extract test batch from data with loci indices\n",
    "def get_batch_test(source: Tensor, i: int, n_predict: int, ndxs ) -> Tuple[Tensor, Tensor]:\n",
    "    data = source[i*bptt:(i+1)*bptt,2*(n_predict-1)+1:][:,:,np.newaxis]\n",
    "    target = source[i*bptt:(i+1)*bptt,:2*(n_predict-1)+1]\n",
    "    if ndxs is not None:\n",
    "        indexes = ndxs[i*bptt:(i+1)*bptt]\n",
    "    else:\n",
    "        indexes = None\n",
    "    return data.to(device), target.to(device), indexes\n",
    "\n",
    "# Training loop for one epoch\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    src_mask = None\n",
    "\n",
    "    bs=list(range(nbatches))\n",
    "    np.random.shuffle(bs)\n",
    "    count=0\n",
    "    for batch in bs:\n",
    "        if count%100==0:print('Batch ',count, ' out of ',nbatches,end='\\r')\n",
    "        count+=1\n",
    "        i=batch\n",
    "        data, targets = get_batch(train_data, i, n_predict=n_predict)\n",
    "        output, output_tf = model(data, src_mask)\n",
    "        loss = 0\n",
    "        for n in range(2*(n_predict-1)+1):\n",
    "            loss += criterion(output[:,n], targets[:,n].type(torch.LongTensor).to(device))\n",
    "        data.detach()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        total_loss = total_loss + loss.item()\n",
    "    return total_loss\n",
    "\n",
    "# Evaluate model on validation or test set\n",
    "def evaluate(model: nn.Module, eval_data: Tensor, type='test') -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = None\n",
    "    nbatches_eval=len(eval_data)//bptt\n",
    "    with torch.no_grad():\n",
    "        for batch in range(nbatches_eval):\n",
    "            data, targets = get_batch(eval_data, batch, n_predict=n_predict)\n",
    "            output, output_tf = model(data, src_mask)\n",
    "            for n in range(2*(n_predict-1)+1):\n",
    "                total_loss += criterion(output[:,n], targets[:,n].type(torch.LongTensor).to(device)).item()\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BbE3h6IqUUYK"
   },
   "outputs": [],
   "source": [
    "# Select the type of XAD to predict (LADs, NADs, or SPECKLES)\n",
    "typeN='LADS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wa5SKnvRNLXu"
   },
   "outputs": [],
   "source": [
    "# Using only 11 histone modification experiments\n",
    "NEXP = 11\n",
    "dpath='./results_w'+str(NEXP)\n",
    "try:\n",
    "    os.mkdir(dpath)\n",
    "except:\n",
    "    print('Directory already created')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "n_neigbors = 14  # Neighboring bins on each side\n",
    "n_predict = 3  # Number of bins to predict\n",
    "nbatches = 200\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Process K562 cell line data\n",
    "cell='K562'\n",
    "pymb=TECSAS.data_process(cell_line=cell, assembly='GRCh38', organism='human',types_path='./TECSAS/TECSAS/share/K562_'+typeN+'/',\n",
    "            signal_type='signal p-value',ref_cell_line_path='./K562_GRCh38_zscore_all', cell_line_path='./K562_GRCh38_zscore_all',\n",
    "            histones=True,tf=False,small_rna=False,total_rna=False,n_states=10,res=50)\n",
    "\n",
    "pymb.ref_chrm_size=pymb.chrm_size\n",
    "train_set,val_set,test_set,all_averages,loci_indx=pymb.training_data(n_neigbors=n_neigbors,train_per=0.8,\n",
    "                                        n_predict=n_predict)\n",
    "\n",
    "# Process additional cell lines (H1, HCT116) and merge datasets if not predicting SPECKLES\n",
    "if typeN!='SPECKLES':\n",
    "    cell='H1'\n",
    "    pymb_h1=TECSAS.data_process(cell_line=cell, assembly='GRCh38', organism='human',types_path='./TECSAS/TECSAS/share/H1_'+typeN+'',\n",
    "                signal_type='signal p-value',ref_cell_line_path='./H1_GRCh38_zscore_all', cell_line_path='./H1_GRCh38_zscore_all',\n",
    "                histones=True,tf=False,small_rna=False,total_rna=False,n_states=10,res=50)\n",
    "\n",
    "    pymb_h1.ref_chrm_size=pymb_h1.chrm_size\n",
    "    train_set_h1,val_set_h1,test_set_h1,all_averages_h1,loci_indx_h1=pymb_h1.training_data(n_neigbors=n_neigbors,train_per=0.8,\n",
    "                                            n_predict=n_predict)\n",
    "\n",
    "    cell='HCT116'\n",
    "    pymb_hc=TECSAS.data_process(cell_line=cell, assembly='GRCh38', organism='human',types_path='./TECSAS/TECSAS/share/HCT116_'+typeN+'',\n",
    "                signal_type='signal p-value',ref_cell_line_path='./HCT116_GRCh38_zscore_all', cell_line_path='./HCT116_GRCh38_zscore_all',\n",
    "                histones=True,tf=False,small_rna=False,total_rna=False,n_states=10,res=50)\n",
    "\n",
    "    pymb_hc.ref_chrm_size=pymb_hc.chrm_size\n",
    "    train_set_hc,val_set_hc,test_set_hc,all_averages_hc,loci_indx_hc=pymb_hc.training_data(n_neigbors=n_neigbors,train_per=0.8,\n",
    "                                            n_predict=n_predict)\n",
    "\n",
    "    # Merge data from all cell lines\n",
    "    all_averages=np.concatenate([all_averages_hc,all_averages_h1,all_averages],axis=1)\n",
    "    train_set=np.concatenate([train_set_hc,train_set_h1,train_set],axis=0)\n",
    "    val_set=np.concatenate([val_set_hc,val_set_h1,val_set],axis=0)\n",
    "    test_set=np.concatenate([test_set_hc,test_set_h1,test_set],axis=0)\n",
    "    loci_indx=np.concatenate([loci_indx_hc,loci_indx_h1,loci_indx],axis=0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_data=torch.tensor(train_set,dtype=torch.float)\n",
    "val_data=torch.tensor(val_set,dtype=torch.float)\n",
    "test_data=torch.tensor(test_set,dtype=torch.float)\n",
    "print(train_data.size(),val_data.size(),test_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gc6o0TZXGCYi"
   },
   "outputs": [],
   "source": [
    "# Load pre-trained parameters and adjust keys for compatibility\n",
    "params = torch.load('results_w11/params_bv_11.pt')\n",
    "\n",
    "new_params = {}\n",
    "for key, value in params.items():\n",
    "    new_key = key.split('module.')[1]\n",
    "    new_params[new_key] = value\n",
    "\n",
    "torch.save(new_params, 'results_w11/modified_params_bv_11.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qc3OvqMCTEOJ"
   },
   "outputs": [],
   "source": [
    "# Initialize model with transfer learning from GM12878\n",
    "torch.cuda.empty_cache()\n",
    "bptt = len(train_data)//nbatches\n",
    "print('Size of batch:',bptt)\n",
    "\n",
    "# Model architecture parameters\n",
    "emsize = 128  # Embedding dimension\n",
    "d_hid = 64  # Hidden dimension in feedforward network\n",
    "nlayers = 2  # Number of transformer encoder layers\n",
    "nhead = 8  # Number of attention heads\n",
    "dropout = 0.01  # Dropout rate\n",
    "nfeatures = train_data.size()[1]-(2*(n_predict-1)+1)\n",
    "ostates = 5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = TECSAS.TECSAS(n_predict, emsize, nhead, d_hid, nlayers, nfeatures, ostates, dropout).to(device)\n",
    "# Load pre-trained encoder from GM12878 training\n",
    "model.load_state_dict(torch.load(dpath+'/modified_params_bv_11.pt'))\n",
    "# Freeze all parameters (transfer learning)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# Modify output layer to predict 2 classes (XAD/nonXAD) instead of 5\n",
    "model.unfl = nn.Unflatten(-1,((2*(n_predict-1)+1),2))\n",
    "model.l2 = nn.Linear(nfeatures*emsize,2*(2*(n_predict-1)+1))\n",
    "initrange = 0.1\n",
    "model.l2.bias.data.zero_()\n",
    "model.l2.weight.data.uniform_(-initrange, initrange)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFVOnuH8TV4r"
   },
   "outputs": [],
   "source": [
    "# Train the model to predict XADs\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model.modules)\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print('Number of params:',params)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_train_loss = float('inf')\n",
    "epochs = 30\n",
    "nepochs = 100\n",
    "\n",
    "lr = 2.5  # learning rate\n",
    "optimizer = torch.optim.SGD(model.l2.parameters(), lr=lr)\n",
    "\n",
    "bsteps=0\n",
    "vlosses=[]\n",
    "# Training loop with adaptive learning rate\n",
    "for epoch in range(1, epochs + 1):\n",
    "    if epoch%nepochs==1:\n",
    "        print('Reseting lr')\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr,weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.5)\n",
    "        train_loss=train(model)\n",
    "    lr_e = scheduler.get_last_lr()[0]\n",
    "    epoch_start_time = time.time()\n",
    "    train_loss=train(model)\n",
    "    elapsed = time.time() - epoch_start_time\n",
    "    val_loss = evaluate(model, val_data, type='val')\n",
    "    print('-' * 89)\n",
    "    print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "        f'valid loss {val_loss:5.2f} | train loss {train_loss:5.2f} | lr {lr_e:2.5f} | best val loss: {best_val_loss:5.2f}')\n",
    "    print('-' * 89)\n",
    "    vlosses.append(val_loss)\n",
    "    # Save best models and adjust learning rate\n",
    "    if train_loss < best_train_loss:\n",
    "        print('Found better train_loss')\n",
    "        best_train_loss = train_loss\n",
    "        torch.save(model.state_dict(), dpath+'/best_train_model_params_'+typeN+'.pt')\n",
    "        bsteps=bsteps+2\n",
    "    if val_loss < best_val_loss:\n",
    "        print('Found better val_loss')\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), dpath+'/best_val_model_params_'+typeN+'.pt')\n",
    "    else:\n",
    "        bsteps=bsteps+1\n",
    "    if bsteps>5:\n",
    "        print('Has not found better train_loss in 5 epochs, reducing lr')\n",
    "        scheduler.step()\n",
    "        print(scheduler.get_last_lr()[0])\n",
    "        bsteps=0\n",
    "print('=' * 89)\n",
    "print(f'| End of training | best val loss {best_val_loss:5.2f} | ')\n",
    "\n",
    "# Plot validation loss over epochs\n",
    "plt.figure()\n",
    "plt.plot(list(range(1, epochs + 1)),vlosses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Val loss')\n",
    "plt.title(typeN+' training')\n",
    "plt.savefig(dpath+'/vloss_'+typeN+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AfPtORSMTSam"
   },
   "outputs": [],
   "source": [
    "# Evaluate the best model on test set\n",
    "k=0\n",
    "f=0\n",
    "for p in ['best_val']:\n",
    "    print(p)\n",
    "    model.load_state_dict(torch.load(dpath+'/'+p+'_model_params_'+typeN+'.pt'))\n",
    "    nbatches_eval=len(test_data)//bptt\n",
    "    l=[]\n",
    "    lt=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in range(nbatches_eval):\n",
    "            data, targets, _ = get_batch_test(test_data, batch, n_predict=n_predict, ndxs = None)\n",
    "            prediction = model(data,None)[0].argmax(dim=-1)[:,n_predict-1].cpu()\n",
    "            l.append(prediction)\n",
    "            lt.append(targets[:,n_predict-1].cpu())\n",
    "    l=np.concatenate(l)\n",
    "    lt=np.concatenate(lt)\n",
    "    print('test:',np.round(np.sum(l==lt)/len(l),4))\n",
    "\n",
    "    # Display confusion matrix\n",
    "    conf_matrix_P=np.round(confusion_matrix(l,lt,normalize='true'),2)\n",
    "    print('BT Confusion matrix:')\n",
    "    print(conf_matrix_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_mV5e-oYvey"
   },
   "outputs": [],
   "source": [
    "# Prepare IMR-90 data for prediction (cross-cell-line validation)\n",
    "cell='IMR-90'\n",
    "pymb=TECSAS.data_process(cell_line=cell, assembly='GRCh38', organism='human',types_path='./TECSAS/TECSAS/share/K562_'+typeN+'/',\n",
    "            signal_type='signal p-value',ref_cell_line_path='./IMR-90_GRCh38_zscore_all', cell_line_path='./IMR-90_GRCh38_zscore_all',\n",
    "            histones=True,tf=False,small_rna=False,total_rna=False,n_states=10,res=50)\n",
    "\n",
    "pymb.ref_chrm_size=pymb.chrm_size\n",
    "test_set,all_averages=pymb.test_data(n_neigbors=n_neigbors,n_predict=n_predict)\n",
    "\n",
    "all_loci = np.array(list(range(len(all_averages[0]))))\n",
    "ntest_loci = all_loci\n",
    "test_data=torch.tensor(test_set,dtype=torch.float)\n",
    "print(test_data.size())\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "bptt = 10\n",
    "print('Size of batch:',bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZDwGT5rhLqv"
   },
   "outputs": [],
   "source": [
    "# Generate predictions for IMR-90 cell line\n",
    "k=0\n",
    "f=0\n",
    "for p in ['best_val']:\n",
    "    print(p)\n",
    "    model.load_state_dict(torch.load(dpath+'/'+p+'_model_params_'+typeN+'.pt'))\n",
    "    nbatches_eval=len(test_data)//bptt\n",
    "    l=[]\n",
    "    lt=[]\n",
    "    loci=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in range(nbatches_eval):\n",
    "            data, targets, batch_loci = get_batch_test(test_data, batch, n_predict=n_predict, ndxs = ntest_loci)\n",
    "            prediction=model(data,None)[0].argmax(dim=-1)[:,n_predict-1].cpu()\n",
    "            loci.append(batch_loci)\n",
    "            l.append(prediction)\n",
    "            lt.append(targets[:,n_predict-1].cpu())\n",
    "    loci=np.concatenate(loci)\n",
    "    l=np.concatenate(l)\n",
    "    lt=np.concatenate(lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6d2qULbziJVP"
   },
   "outputs": [],
   "source": [
    "# Save predictions as a BED file for genome browser visualization\n",
    "# Define color codes for different classes\n",
    "info = {\n",
    "    0: ('1', \"245,47,47\"),\n",
    "    1: ('4', \"47,47,224\"),\n",
    "    \"NA\": (0, \"255,255,255\"),\n",
    "    \"A1\": (1, \"245,47,47\"),\n",
    "    \"A2\": (2, \"145,47,47\"),\n",
    "    \"B1\": (3, \"47,187,224\"),\n",
    "    \"B2\": (4, \"47,47,224\"),\n",
    "    \"B3\": (5, \"47,47,139\"),\n",
    "    \"B4\": (6, \"75,0,130\"),\n",
    "    \"A\": (1, \"245,47,47\"),\n",
    "    \"B\": (2, \"47,187,224\"),\n",
    "    }\n",
    "\n",
    "# Convert genomic loci to chromosome coordinates\n",
    "offset=0\n",
    "print(np.sum(pymb.chrm_size[:22]),np.max(ntest_loci),np.max(loci))\n",
    "cid=0\n",
    "tmpc=pymb.chrm_size[cid]\n",
    "loci=loci+14\n",
    "with open(dpath+'/'+typeN+'_IMR-90.txt','w') as f:\n",
    "    for i in range(len(loci)):\n",
    "        if loci[i]-offset>tmpc-1:\n",
    "            offset=loci[i]\n",
    "            cid=cid+1\n",
    "            tmpc=pymb.chrm_size[cid]\n",
    "        chromosome=cid+1\n",
    "        position=loci[i]-offset\n",
    "        resolution=50000\n",
    "        # Write BED format line\n",
    "        text=\"chr\" + str(chromosome) + \"\\t\" + str((position - 1) * resolution) + \"\\t\"\n",
    "        text=text+str(position * resolution) + \"\\t\" + str(l[i]) + \"\\t\" + info[l[i]][0] + \"\\t.\\t\"\n",
    "        text=text+str((position - 1) * resolution) + \"\\t\" + str(position * resolution) + \"\\t \" + info[l[i]][1]\n",
    "        f.write(text+'\\n')\n",
    "print(np.unique(l,return_counts=True))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
